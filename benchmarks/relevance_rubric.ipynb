{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "014554f5-68a6-4c94-9683-7db8afc7b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a89693d2-65b7-4547-a539-43c3f4db9325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = 'langchain_api_key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1a304f0-70ee-47ee-a9c5-8374680003ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = 'openai_api_key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "306ce480-e8a3-416e-b61b-2dfca9774065",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99077852-760d-4034-8d8b-777414e0f2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"question\", \"answer\"],\n",
    "    template=\"\"\"\n",
    "You are an evaluator for a knowledge model.  \n",
    "Your task is to judge the RELEVANCE of the ANSWER to the USER QUESTION.  \n",
    "\n",
    "### Evaluation Goal:\n",
    "- Check how well the answer focuses on the user's question.\n",
    "- Penalize answers that contain unnecessary or unrelated details.\n",
    "\n",
    "### USER QUESTION:\n",
    "{question}\n",
    "\n",
    "### ANSWER:\n",
    "{answer}\n",
    "\n",
    "### Scoring Criteria:\n",
    "1 – Very irrelevant. The answer does not address the question or contains mostly unrelated content.  \n",
    "2 – Somewhat irrelevant. The answer touches on the question but is filled with unnecessary or unrelated details.  \n",
    "3 – Moderately relevant. The answer addresses the question but includes some off-topic information.  \n",
    "4 – Mostly relevant. The answer is focused on the question with only minor irrelevant parts.  \n",
    "5 – Fully relevant. The answer directly addresses the question without any irrelevant details.\n",
    "\n",
    "Respond only in JSON:\n",
    "{{\n",
    "  \"score\": <number>,\n",
    "  \"justification\": \"<brief reason>\"\n",
    "}}\n",
    "\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7af1a772-6ae2-4486-8e9e-47b03ffe4d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_chain = (prompt_template | llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b5441708-90a9-456e-8560-61e0333b2051",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "what is health according to the author?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e98c2346-ec29-4765-88fd-0071e0581102",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_text = \"\"\"\n",
    "According to the author, overall health of citizens could be addressed by other methods because health is influenced by many factors, not just exercise. \n",
    "\"\"\"\n",
    "\n",
    "# answer_text = \"\"\"\n",
    "# According to the author, the overall health of citizens can be addressed by methods other than launching more sports facilities because health depends on multiple factors, not solely on access to exercise. While the author acknowledges that increasing sports facilities can encourage physical activity and improve concentration, optimism, and productivity—as seen in Hanoi, where citizens became healthier due to local exercise equipment—this approach only partially improves public health. \n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8879f40f-c948-4e17-9cc1-9fad11a968a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluation_chain.invoke({\"question\": question, \"answer\": answer_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c0c520c-ddf3-41c0-a088-c391f587e1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"score\": 1,\n",
      "  \"justification\": \"The answer does not directly address the user's question about the author's definition of health. It instead discusses methods to address health and factors influencing it, which is unrelated to the specific question asked.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3f9699-ee65-41ee-bf87-1a5f8da789f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RAG Env)",
   "language": "python",
   "name": "my_venv_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
